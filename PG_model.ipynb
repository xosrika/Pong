{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import utils as np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout,  Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mspacman_color = 210 + 164 + 74\n",
    "def preprocess_observation(obs):\n",
    "    img = obs[33:209:2, ::2] # crop and downsize\n",
    "    img = img.sum(axis=2) # to greyscale\n",
    "    img[img==mspacman_color] = 0 # Improve contrast\n",
    "    img = (img // 3 - 128).astype(np.int8) # normalize from -128 to 127\n",
    "    return img.reshape(88, 80, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_discounted_R(R, discount_rate=0.99):\n",
    "    \n",
    "    discounted_r = np.zeros_like(R, dtype=np.float32)\n",
    "    running_add = 0\n",
    "    for t in reversed(range(len(R))):\n",
    "\n",
    "        running_add = running_add * discount_rate + R[t]\n",
    "        discounted_r[t] = running_add\n",
    "\n",
    "    discounted_r -= discounted_r.mean() / discounted_r.std()\n",
    "\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dims=[32, 32]):\n",
    "        \n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.__build_network(input_dim, output_dim, hidden_dims)\n",
    "        self.__build_train_fn()\n",
    "\n",
    "    def __build_network(self, input_dim, output_dim, hidden_dims=[32, 32]):\n",
    "        \n",
    "        self.model = Sequential()\n",
    "       \n",
    "        # self.model.add(Dense(32, activation='relu', kernel_initializer = 'glorot_normal', input_shape=[input_dim]))\n",
    "        # self.model.add(Dense(32, activation='relu', kernel_initializer = 'glorot_normal'))\n",
    "        self.model.add(Conv2D(15, (3, 3), activation='sigmoid', input_shape=input_dim))\n",
    "        self.model.add(Conv2D(15, (3, 3), activation='relu', ))\n",
    "#         self.model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(100, activation='relu'))        \n",
    "        \n",
    "        self.model.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "    def __build_train_fn(self):\n",
    "        \n",
    "        action_prob_placeholder = self.model.output\n",
    "        action_onehot_placeholder = K.placeholder(shape=(None, self.output_dim),\n",
    "                                                  name=\"action_onehot\")\n",
    "        discount_reward_placeholder = K.placeholder(shape=(None,),\n",
    "                                                    name=\"discount_reward\")\n",
    "\n",
    "        action_prob = K.sum(action_prob_placeholder * action_onehot_placeholder, axis=1)\n",
    "        log_action_prob = K.log(action_prob)\n",
    "\n",
    "        loss = - log_action_prob * discount_reward_placeholder\n",
    "        loss = K.mean(loss)\n",
    "\n",
    "        adam = optimizers.Adam()\n",
    "\n",
    "        updates = adam.get_updates(params=self.model.trainable_weights,\n",
    "                                   # constraints=[],\n",
    "                                   loss=loss)\n",
    "\n",
    "        self.train_fn = K.function(inputs=[self.model.input,\n",
    "                                           action_onehot_placeholder,\n",
    "                                           discount_reward_placeholder],\n",
    "                                   outputs=[],\n",
    "                                   updates=updates)\n",
    "\n",
    "    def get_action(self, state):\n",
    "        \n",
    "        shape = state.shape\n",
    "        \n",
    "        state = np.expand_dims(state, axis=0)\n",
    "\n",
    "        \n",
    "        action_prob = np.squeeze(self.model.predict(state))\n",
    "        # assert len(action_prob) == self.output_dim, \"{} != {}\".format(len(action_prob), self.output_dim)\n",
    "        return np.random.choice(np.arange(self.output_dim), p=action_prob)\n",
    "\n",
    "    def fit(self, S, A, R):\n",
    "       \n",
    "        action_onehot = np_utils.to_categorical(A, num_classes=self.output_dim)\n",
    "        discount_reward = compute_discounted_R(R)\n",
    "\n",
    "        \n",
    "        self.train_fn([S, action_onehot, discount_reward])\n",
    "        \n",
    "    def save(self):\n",
    "        self.model.save_weights(\"modelFile.h5\")\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load_weights(\"modelFile.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episode(env, agent):\n",
    "    \"\"\"Returns an episode reward\n",
    "    (1) Play until the game is done\n",
    "    (2) The agent will choose an action according to the policy\n",
    "    (3) When it's done, it will train from the game play\n",
    "    Args:\n",
    "        env (gym.env): Gym environment\n",
    "        agent (Agent): Game Playing Agent\n",
    "    Returns:\n",
    "        total_reward (int): total reward earned during the whole episode\n",
    "    \"\"\"\n",
    "    done = False\n",
    "    S = []\n",
    "    A = []\n",
    "    R = []\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        s = preprocess_observation(s)\n",
    "        a = 0\n",
    "        if(len(S) == 0):\n",
    "            a = agent.get_action(s)\n",
    "        else:\n",
    "            a = agent.get_action(np.maximum(s, S[-1]))    \n",
    "        s2, r, done, info = env.step(a)\n",
    "        total_reward += r\n",
    "\n",
    "        S.append(s)\n",
    "        A.append(a)\n",
    "        R.append(r)\n",
    "\n",
    "        s = s2\n",
    "        \n",
    "        if done:\n",
    "            S = np.array(S)\n",
    "            A = np.array(A)\n",
    "            R = np.array(R)\n",
    "            agent.fit(S, A, R)\n",
    "\n",
    "    return total_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "input_dim = [88, 80, 1]\n",
    "output_dim = env.action_space.n\n",
    "agent = Agent(input_dim, output_dim, [16, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -21.0\n",
      "1 -21.0\n",
      "2 -21.0\n",
      "3 -21.0\n",
      "4 -21.0\n",
      "5 -21.0\n",
      "6 -21.0\n",
      "7 -21.0\n",
      "8 -21.0\n",
      "9 -21.0\n",
      "10 -21.0\n",
      "11 -21.0\n",
      "12 -21.0\n",
      "13 -21.0\n",
      "14 -21.0\n",
      "15 -21.0\n",
      "16 -21.0\n",
      "17 -21.0\n",
      "18 -21.0\n",
      "19 -21.0\n",
      "20 -21.0\n",
      "21 -21.0\n",
      "22 -21.0\n",
      "23 -21.0\n",
      "24 -21.0\n",
      "25 -21.0\n",
      "26 -21.0\n",
      "27 -21.0\n",
      "28 -21.0\n",
      "29 -21.0\n",
      "30 -21.0\n",
      "31 -21.0\n",
      "32 -21.0\n",
      "33 -21.0\n",
      "34 -21.0\n",
      "35 -21.0\n",
      "36 -21.0\n",
      "37 -21.0\n",
      "38 -21.0\n",
      "39 -21.0\n",
      "40 -21.0\n",
      "41 -21.0\n",
      "42 -21.0\n",
      "43 -21.0\n",
      "44 -21.0\n",
      "45 -21.0\n",
      "46 -21.0\n",
      "47 -21.0\n",
      "48 -21.0\n",
      "49 -21.0\n",
      "50 -21.0\n",
      "51 -21.0\n",
      "52 -21.0\n",
      "53 -21.0\n",
      "54 -21.0\n",
      "55 -21.0\n",
      "56 -21.0\n",
      "57 -21.0\n",
      "58 -21.0\n",
      "59 -21.0\n",
      "60 -21.0\n",
      "61 -21.0\n",
      "62 -21.0\n",
      "63 -21.0\n",
      "64 -21.0\n",
      "65 -21.0\n",
      "66 -21.0\n",
      "67 -21.0\n",
      "68 -21.0\n",
      "69 -21.0\n",
      "70 -21.0\n",
      "71 -21.0\n",
      "72 -21.0\n",
      "73 -21.0\n",
      "74 -21.0\n",
      "75 -21.0\n",
      "76 -21.0\n",
      "77 -21.0\n",
      "78 -21.0\n",
      "79 -21.0\n",
      "80 -21.0\n",
      "81 -21.0\n",
      "82 -21.0\n",
      "83 -21.0\n",
      "84 -21.0\n",
      "85 -21.0\n",
      "86 -21.0\n",
      "87 -21.0\n",
      "88 -21.0\n",
      "89 -21.0\n",
      "90 -21.0\n",
      "91 -21.0\n",
      "92 -21.0\n",
      "93 -21.0\n",
      "94 -21.0\n",
      "95 -21.0\n",
      "96 -21.0\n",
      "97 -21.0\n",
      "98 -21.0\n",
      "99 -21.0\n",
      "100 -21.0\n",
      "101 -21.0\n",
      "102 -21.0\n",
      "103 -21.0\n",
      "104 -21.0\n",
      "105 -21.0\n",
      "106 -21.0\n",
      "107 -21.0\n",
      "108 -21.0\n",
      "109 -21.0\n",
      "110 -21.0\n",
      "111 -21.0\n",
      "112 -21.0\n",
      "113 -21.0\n",
      "114 -21.0\n",
      "115 -21.0\n",
      "116 -21.0\n",
      "117 -21.0\n",
      "118 -21.0\n",
      "119 -21.0\n",
      "120 -21.0\n",
      "121 -21.0\n",
      "122 -21.0\n",
      "123 -21.0\n",
      "124 -21.0\n",
      "125 -21.0\n",
      "126 -21.0\n",
      "127 -21.0\n",
      "128 -21.0\n",
      "129 -21.0\n",
      "130 -21.0\n",
      "131 -21.0\n",
      "132 -21.0\n",
      "133 -21.0\n",
      "134 -21.0\n",
      "135 -21.0\n",
      "136 -21.0\n",
      "137 -21.0\n",
      "138 -21.0\n",
      "139 -21.0\n",
      "140 -21.0\n",
      "141 -21.0\n",
      "142 -21.0\n",
      "143 -21.0\n",
      "144 -21.0\n",
      "145 -21.0\n",
      "146 -21.0\n",
      "147 -21.0\n",
      "148 -21.0\n",
      "149 -21.0\n",
      "150 -21.0\n",
      "151 -21.0\n",
      "152 -21.0\n",
      "153 -21.0\n",
      "154 -21.0\n",
      "155 -21.0\n",
      "156 -21.0\n",
      "157 -21.0\n",
      "158 -21.0\n",
      "159 -21.0\n",
      "160 -21.0\n",
      "161 -21.0\n",
      "162 -21.0\n",
      "163 -21.0\n",
      "164 -21.0\n",
      "165 -21.0\n",
      "166 -21.0\n",
      "167 -21.0\n",
      "168 -21.0\n",
      "169 -21.0\n",
      "170 -21.0\n",
      "171 -21.0\n",
      "172 -21.0\n",
      "173 -21.0\n",
      "174 -21.0\n",
      "175 -21.0\n",
      "176 -21.0\n",
      "177 -21.0\n",
      "178 -21.0\n",
      "179 -21.0\n",
      "180 -21.0\n",
      "181 -21.0\n",
      "182 -21.0\n",
      "183 -21.0\n",
      "184 -21.0\n",
      "185 -21.0\n",
      "186 -21.0\n",
      "187 -21.0\n",
      "188 -21.0\n",
      "189 -21.0\n",
      "190 -21.0\n",
      "191 -21.0\n",
      "192 -21.0\n",
      "193 -21.0\n",
      "194 -21.0\n",
      "195 -21.0\n",
      "196 -21.0\n",
      "197 -21.0\n",
      "198 -21.0\n",
      "199 -21.0\n",
      "200 -21.0\n",
      "201 -21.0\n",
      "202 -21.0\n",
      "203 -21.0\n",
      "204 -21.0\n",
      "205 -21.0\n",
      "206 -21.0\n",
      "207 -21.0\n",
      "208 -21.0\n",
      "209 -21.0\n",
      "210 -21.0\n",
      "211 -21.0\n",
      "212 -21.0\n",
      "213 -21.0\n",
      "214 -21.0\n",
      "215 -21.0\n",
      "216 -21.0\n",
      "217 -21.0\n",
      "218 -21.0\n",
      "219 -21.0\n",
      "220 -21.0\n",
      "221 -21.0\n",
      "222 -21.0\n",
      "223 -21.0\n",
      "224 -21.0\n",
      "225 -21.0\n",
      "226 -21.0\n",
      "227 -21.0\n",
      "228 -21.0\n",
      "229 -21.0\n",
      "230 -21.0\n",
      "231 -21.0\n",
      "232 -21.0\n",
      "233 -21.0\n",
      "234 -21.0\n",
      "235 -21.0\n",
      "236 -21.0\n",
      "237 -21.0\n",
      "238 -21.0\n",
      "239 -21.0\n",
      "240 -21.0\n",
      "241 -21.0\n",
      "242 -21.0\n",
      "243 -21.0\n",
      "244 -21.0\n",
      "245 -21.0\n",
      "246 -21.0\n",
      "247 -21.0\n",
      "248 -21.0\n",
      "249 -21.0\n",
      "250 -21.0\n",
      "251 -21.0\n",
      "252 -21.0\n",
      "253 -21.0\n",
      "254 -21.0\n",
      "255 -21.0\n",
      "256 -21.0\n",
      "257 -21.0\n",
      "258 -21.0\n",
      "259 -21.0\n",
      "260 -21.0\n",
      "261 -21.0\n",
      "262 -21.0\n",
      "263 -21.0\n",
      "264 -21.0\n",
      "265 -21.0\n",
      "266 -21.0\n",
      "267 -21.0\n",
      "268 -21.0\n",
      "269 -21.0\n",
      "270 -21.0\n",
      "271 -21.0\n",
      "272 -21.0\n",
      "273 -21.0\n",
      "274 -21.0\n",
      "275 -21.0\n",
      "276 -21.0\n",
      "277 -21.0\n",
      "278 -21.0\n",
      "279 -21.0\n",
      "280 -21.0\n",
      "281 -21.0\n",
      "282 -21.0\n",
      "283 -21.0\n",
      "284 -21.0\n",
      "285 -21.0\n",
      "286 -21.0\n",
      "287 -21.0\n",
      "288 -21.0\n",
      "289 -21.0\n",
      "290 -21.0\n",
      "291 -21.0\n",
      "292 -21.0\n",
      "293 -21.0\n",
      "294 -21.0\n",
      "295 -21.0\n",
      "296 -21.0\n",
      "297 -21.0\n",
      "298 -21.0\n",
      "299 -21.0\n",
      "300 -21.0\n",
      "301 -21.0\n",
      "302 -21.0\n",
      "303 -21.0\n",
      "304 -21.0\n",
      "305 -21.0\n",
      "306 -21.0\n",
      "307 -21.0\n",
      "308 -21.0\n",
      "309 -21.0\n",
      "310 -21.0\n",
      "311 -21.0\n",
      "312 -21.0\n",
      "313 -21.0\n",
      "314 -21.0\n",
      "315 -21.0\n",
      "316 -21.0\n",
      "317 -21.0\n",
      "318 -21.0\n",
      "319 -21.0\n",
      "320 -21.0\n",
      "321 -21.0\n",
      "322 -21.0\n",
      "323 -21.0\n",
      "324 -21.0\n",
      "325 -21.0\n",
      "326 -21.0\n",
      "327 -21.0\n",
      "328 -21.0\n",
      "329 -21.0\n",
      "330 -21.0\n",
      "331 -21.0\n",
      "332 -21.0\n",
      "333 -21.0\n",
      "334 -21.0\n",
      "335 -21.0\n",
      "336 -21.0\n",
      "337 -21.0\n",
      "338 -21.0\n",
      "339 -21.0\n",
      "340 -21.0\n",
      "341 -21.0\n",
      "342 -21.0\n",
      "343 -21.0\n",
      "344 -21.0\n",
      "345 -21.0\n",
      "346 -21.0\n",
      "347 -21.0\n",
      "348 -21.0\n",
      "349 -21.0\n",
      "350 -21.0\n",
      "351 -21.0\n",
      "352 -21.0\n",
      "353 -21.0\n",
      "354 -21.0\n",
      "355 -21.0\n",
      "356 -21.0\n",
      "357 -21.0\n",
      "358 -21.0\n",
      "359 -21.0\n",
      "360 -21.0\n",
      "361 -21.0\n",
      "362 -21.0\n",
      "363 -21.0\n",
      "364 -21.0\n",
      "365 -21.0\n",
      "366 -21.0\n",
      "367 -21.0\n",
      "368 -21.0\n",
      "369 -21.0\n",
      "370 -21.0\n",
      "371 -21.0\n",
      "372 -21.0\n",
      "373 -21.0\n",
      "374 -21.0\n",
      "375 -21.0\n",
      "376 -21.0\n",
      "377 -21.0\n",
      "378 -21.0\n",
      "379 -21.0\n",
      "380 -21.0\n",
      "381 -21.0\n",
      "382 -21.0\n",
      "383 -21.0\n",
      "384 -21.0\n",
      "385 -21.0\n",
      "386 -21.0\n",
      "387 -21.0\n",
      "388 -21.0\n",
      "389 -21.0\n",
      "390 -21.0\n",
      "391 -21.0\n",
      "392 -21.0\n",
      "393 -21.0\n",
      "394 -21.0\n",
      "395 -21.0\n",
      "396 -21.0\n",
      "397 -21.0\n",
      "398 -21.0\n",
      "399 -21.0\n",
      "400 -21.0\n",
      "401 -21.0\n",
      "402 -21.0\n",
      "403 -21.0\n",
      "404 -21.0\n",
      "405 -21.0\n",
      "406 -21.0\n",
      "407 -21.0\n",
      "408 -21.0\n",
      "409 -21.0\n",
      "410 -21.0\n",
      "411 -21.0\n",
      "412 -21.0\n",
      "413 -21.0\n",
      "414 -21.0\n",
      "415 -21.0\n",
      "416 -21.0\n",
      "417 -21.0\n",
      "418 -21.0\n",
      "419 -21.0\n",
      "420 -21.0\n",
      "421 -21.0\n",
      "422 -21.0\n",
      "423 -21.0\n",
      "424 -21.0\n",
      "425 -21.0\n",
      "426 -21.0\n",
      "427 -21.0\n",
      "428 -21.0\n",
      "429 -21.0\n",
      "430 -21.0\n",
      "431 -21.0\n",
      "432 -21.0\n",
      "433 -21.0\n",
      "434 -21.0\n",
      "435 -21.0\n",
      "436 -21.0\n",
      "437 -21.0\n",
      "438 -21.0\n",
      "439 -21.0\n",
      "440 -21.0\n",
      "441 -21.0\n",
      "442 -21.0\n",
      "443 -21.0\n",
      "444 -21.0\n",
      "445 -21.0\n",
      "446 -21.0\n",
      "447 -21.0\n",
      "448 -21.0\n",
      "449 -21.0\n",
      "450 -21.0\n",
      "451 -21.0\n",
      "452 -21.0\n",
      "453 -21.0\n",
      "454 -21.0\n",
      "455 -21.0\n",
      "456 -21.0\n",
      "457 -21.0\n",
      "458 -21.0\n",
      "459 -21.0\n",
      "460 -21.0\n",
      "461 -21.0\n",
      "462 -21.0\n",
      "463 -21.0\n",
      "464 -21.0\n",
      "465 -21.0\n",
      "466 -21.0\n",
      "467 -21.0\n",
      "468 -21.0\n",
      "469 -21.0\n",
      "470 -21.0\n",
      "471 -21.0\n",
      "472 -21.0\n",
      "473 -21.0\n",
      "474 -21.0\n",
      "475 -21.0\n",
      "476 -21.0\n",
      "477 -21.0\n",
      "478 -21.0\n",
      "479 -21.0\n",
      "480 -21.0\n",
      "481 -21.0\n",
      "482 -21.0\n",
      "483 -21.0\n",
      "484 -21.0\n",
      "485 -21.0\n",
      "486 -21.0\n",
      "487 -21.0\n",
      "488 -21.0\n",
      "489 -21.0\n",
      "490 -21.0\n",
      "491 -21.0\n",
      "492 -21.0\n",
      "493 -21.0\n",
      "494 -21.0\n",
      "495 -21.0\n",
      "496 -21.0\n",
      "497 -21.0\n",
      "498 -21.0\n",
      "499 -21.0\n",
      "500 -21.0\n",
      "501 -21.0\n",
      "502 -21.0\n",
      "503 -21.0\n",
      "504 -21.0\n",
      "505 -21.0\n",
      "506 -21.0\n",
      "507 -21.0\n",
      "508 -21.0\n",
      "509 -21.0\n",
      "510 -21.0\n",
      "511 -21.0\n",
      "512 -21.0\n",
      "513 -21.0\n",
      "514 -21.0\n",
      "515 -21.0\n",
      "516 -21.0\n",
      "517 -21.0\n",
      "518 -21.0\n",
      "519 -21.0\n",
      "520 -21.0\n",
      "521 -21.0\n",
      "522 -21.0\n",
      "523 -21.0\n",
      "524 -21.0\n",
      "525 -21.0\n",
      "526 -21.0\n",
      "527 -21.0\n",
      "528 -21.0\n",
      "529 -21.0\n",
      "530 -21.0\n",
      "531 -21.0\n",
      "532 -21.0\n",
      "533 -21.0\n",
      "534 -21.0\n",
      "535 -21.0\n",
      "536 -21.0\n",
      "537 -21.0\n",
      "538 -21.0\n",
      "539 -21.0\n",
      "540 -21.0\n",
      "541 -21.0\n",
      "542 -21.0\n",
      "543 -21.0\n",
      "544 -21.0\n",
      "545 -21.0\n",
      "546 -21.0\n",
      "547 -21.0\n",
      "548 -21.0\n",
      "549 -21.0\n",
      "550 -21.0\n",
      "551 -21.0\n",
      "552 -21.0\n",
      "553 -21.0\n",
      "554 -21.0\n",
      "555 -21.0\n",
      "556 -21.0\n",
      "557 -21.0\n",
      "558 -21.0\n",
      "559 -21.0\n",
      "560 -21.0\n",
      "561 -21.0\n",
      "562 -21.0\n",
      "563 -21.0\n",
      "564 -21.0\n",
      "565 -21.0\n",
      "566 -21.0\n",
      "567 -21.0\n",
      "568 -21.0\n",
      "569 -21.0\n",
      "570 -21.0\n",
      "571 -21.0\n",
      "572 -21.0\n",
      "573 -21.0\n",
      "574 -21.0\n",
      "575 -21.0\n",
      "576 -21.0\n",
      "577 -21.0\n",
      "578 -21.0\n",
      "579 -21.0\n",
      "580 -21.0\n",
      "581 -21.0\n",
      "582 -21.0\n",
      "583 -21.0\n",
      "584 -21.0\n",
      "585 -21.0\n",
      "586 -21.0\n",
      "587 -21.0\n",
      "588 -21.0\n",
      "589 -21.0\n",
      "590 -21.0\n",
      "591 -21.0\n",
      "592 -21.0\n",
      "593 -21.0\n",
      "594 -21.0\n",
      "595 -21.0\n",
      "596 -21.0\n",
      "597 -21.0\n",
      "598 -21.0\n",
      "599 -21.0\n",
      "600 -21.0\n",
      "601 -21.0\n",
      "602 -21.0\n",
      "603 -21.0\n",
      "604 -21.0\n",
      "605 -21.0\n",
      "606 -21.0\n",
      "607 -21.0\n",
      "608 -21.0\n",
      "609 -21.0\n",
      "610 -21.0\n",
      "611 -21.0\n",
      "612 -21.0\n",
      "613 -21.0\n",
      "614 -21.0\n",
      "615 -21.0\n",
      "616 -21.0\n",
      "617 -21.0\n",
      "618 -21.0\n",
      "619 -21.0\n",
      "620 -21.0\n",
      "621 -21.0\n",
      "622 -21.0\n",
      "623 -21.0\n",
      "624 -21.0\n",
      "625 -21.0\n",
      "626 -21.0\n",
      "627 -21.0\n",
      "628 -21.0\n",
      "629 -21.0\n",
      "630 -21.0\n",
      "631 -21.0\n",
      "632 -21.0\n",
      "633 -21.0\n",
      "634 -21.0\n",
      "635 -21.0\n",
      "636 -21.0\n",
      "637 -21.0\n",
      "638 -21.0\n",
      "639 -21.0\n",
      "640 -21.0\n",
      "641 -21.0\n",
      "642 -21.0\n",
      "643 -21.0\n",
      "644 -21.0\n",
      "645 -21.0\n",
      "646 -21.0\n",
      "647 -21.0\n",
      "648 -21.0\n",
      "649 -21.0\n",
      "650 -21.0\n",
      "651 -21.0\n",
      "652 -21.0\n",
      "653 -21.0\n",
      "654 -21.0\n",
      "655 -21.0\n",
      "656 -21.0\n",
      "657 -21.0\n",
      "658 -21.0\n",
      "659 -21.0\n",
      "660 -21.0\n",
      "661 -21.0\n",
      "662 -21.0\n",
      "663 -21.0\n",
      "664 -21.0\n",
      "665 -21.0\n",
      "666 -21.0\n",
      "667 -21.0\n",
      "668 -21.0\n",
      "669 -21.0\n",
      "670 -21.0\n",
      "671 -21.0\n",
      "672 -21.0\n",
      "673 -21.0\n",
      "674 -21.0\n",
      "675 -21.0\n",
      "676 -21.0\n",
      "677 -21.0\n",
      "678 -21.0\n",
      "679 -21.0\n",
      "680 -21.0\n",
      "681 -21.0\n",
      "682 -21.0\n",
      "683 -21.0\n",
      "684 -21.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = 0;\n",
    "while True:\n",
    "    a += 1\n",
    "    reward = run_episode(env, agent)\n",
    "    print(episode, reward)\n",
    "    if( a )\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
